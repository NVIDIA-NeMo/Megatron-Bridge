import numpy as np

from tqdm import tqdm

from megatron.bridge.data.datasets.packing_utils import (
    find_first_bin_that_fits,
    create_packing_strategy,
    fill_packing_strategy,
    first_fit_decreasing,
    first_fit_shuffle,
    create_hist,
    first_fit,
)


def fill_packing_strategy(
    assignments, sequences, pack_size: int, pad_id: int
):
    """
    Fills the packing strategy with actual sequence data based on assignments and sequence information.

    This function takes the assignments generated by the packing algorithm (containing sequence length indices),
    the original sequences data, and the pack size. It iterates through the assignments, retrieves the corresponding
    sequences from the sequences dictionary, and constructs the final output data structure with input IDs, loss masks
    (if available), and starting indices for each sequence in a packed sequence.

    Args:
          assignments: A list of lists, where each inner list represents a bin and contains the indices of the
                        sequence lengths assigned to that bin (output of 'create_packing_strategy').
          sequences: A dictionary where keys are sequence lengths and values are lists of corresponding sequences
                      from the dataset (output of 'create_hist').
          pack_size: The maximum capacity of each bin.
          pad_id: The tokenizer's padding token.

    Returns:
          output_data: A list of dictionaries, where each dictionary represents a packed sequence with its input IDs,
                        loss mask (if available), and starting indices.
    """
    ifile_handles = dict()
    for seq_len in tqdm(range(pack_size + 1)):
        per_seq_data = sequences[seq_len]
        if len(per_seq_data) > 0:
            perm = np.random.permutation(len(per_seq_data))
            input_ids = np.array([x["input_ids"] for x in per_seq_data])[perm].tolist()
            try:
                loss_mask = np.array(
                    [
                        [
                            # (x['answer_start_idx'] - 1) because we want to train on the output
                            # after the last context token
                            idx >= (x["answer_start_idx"] - 1) and x["input_ids"][idx] != pad_id
                            for idx in range(len(x["input_ids"]))
                        ]
                        for x in per_seq_data
                    ]
                )[perm].tolist()
            except KeyError:
                loss_mask = None
            ifile_handles[seq_len] = (input_ids, loss_mask)

    input_ids, loss_mask, seq_start_id = {}, {}, {}

    for oindex, assignment in tqdm(enumerate(assignments), total=len(assignments)):
        _input_ids, _loss_mask, _seq_start_id = [], [], [0]

        for seq_length in assignment:
            #print(ifile_handles)
            _input_ids.extend(ifile_handles[seq_length][0].pop())
            _loss_mask.extend(ifile_handles[seq_length][1].pop())
            _seq_start_id.append(len(_input_ids))

        input_ids[oindex] = _input_ids
        loss_mask[oindex] = _loss_mask
        seq_start_id[oindex] = _seq_start_id[:-1]

    output_data = []
    for i in range(len(input_ids)):
        item_dict = {"input_ids": input_ids[i], "loss_mask": loss_mask[i], "seq_start_id": seq_start_id[i]}
        output_data.append(item_dict)

    assert all(not seq[0] for seq in ifile_handles.values()), "Error: There are items left over from the assignment"
    assert all(not seq[1] for seq in ifile_handles.values()), "Error: There are items left over from the assignment"
    return output_data


hist = [1, 77]
pack_size = 1

assignments, packing_metadata = create_packing_strategy(hist, pack_size)

#assert packing_metadata == {'dataset_max_seqlen': 5, 'max_samples_per_bin': 89}

sequences = {
    0: [{"input_ids": [19, 0, 21413, 1873], "answer_start_idx": 0} for i in range(128)],
    1: [{"input_ids": [17, 35, 2, 11], "answer_start_idx": 0} for i in range(128)],
    2: [{"input_ids": [111, 9999, 5, 6], "answer_start_idx": 0} for i in range(128)],
}

data = fill_packing_strategy(assignments, sequences, 1, 1000)