# Copyright (c) 2025, NVIDIA CORPORATION.  All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Example FLUX pretrain configuration override file
# This file shows common overrides for FLUX pretraining

# Model configuration
model:
  # Parallelism settings
  tensor_model_parallel_size: 4
  pipeline_model_parallel_size: 1
  context_parallel_size: 1
  sequence_parallel: false

  # FLUX architecture (FLUX-schnell defaults)
  num_joint_layers: 19
  num_single_layers: 38
  hidden_size: 3072
  num_attention_heads: 24
  in_channels: 64
  context_dim: 4096

  # For FLUX-dev, set guidance_embed: true
  guidance_embed: false
  guidance_scale: 3.5

# Training configuration
train:
  train_iters: 10000
  eval_interval: 2000
  eval_iters: 32
  global_batch_size: 64
  micro_batch_size: 1

# Optimizer configuration
optimizer:
  lr: 1.0e-4

# Checkpoint configuration
checkpoint:
  save_interval: 2000

# Logger configuration
logger:
  log_interval: 1
